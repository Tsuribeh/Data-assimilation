{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1スケール40変数完全モデル・完全観測でのETKF\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "import random\n",
    "\n",
    "\n",
    "# Simulation parameters\n",
    "t0 = 0.0\n",
    "dt = 1.e-2\n",
    "assimilation_interval = 5#12  # 同化間隔\n",
    "n_timestep = assimilation_interval * 4 * 365  # 合計タイムステップ\n",
    "n_data = n_timestep // assimilation_interval  # データポイント数\n",
    "km = 40#8  # slow variables\n",
    "jm = 0\n",
    "# kmjm = km * jm  # fast variables\n",
    "F_ex = 20.0\n",
    "m = 100 #n of ensemble member\n",
    "#Assimilation parameters\n",
    "rho=1.0\n",
    "\n",
    "# Constants for the two-way coupled system(not used)\n",
    "h = 0\n",
    "b = 10.0\n",
    "c = 0\n",
    "\n",
    "\n",
    "\n",
    "# Load binary data for true values\n",
    "with open(\"1scale_t_truedata_fort_50span.bin\", \"rb\") as f_t:\n",
    "    data_time = np.frombuffer(f_t.read(), dtype=np.float64)\n",
    "\n",
    "print(data_time)\n",
    "\n",
    "\n",
    "with open(\"1scale_xtrue_timeseries_km40_F8_50span.bin\", \"rb\") as f_x1:\n",
    "    true_data_x = np.frombuffer(f_x1.read(), dtype=np.float64)\n",
    "\n",
    "true_data_x = true_data_x.reshape((n_data, km))\n",
    "\n",
    "\n",
    "\n",
    "len_x = km\n",
    "len_obs = km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def model_forecast(t,X,km):\n",
    "    model = np.empty(km)  # Initialize the model array\n",
    "    for k in range(km):\n",
    "        model[k] =  X[(k - 1) % km] * (X[(k + 1) % km] - X[(k - 2) % km]) - X[k] + F_ex\n",
    "    return model\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def model_nature(t,X,km,jm): #km:1scale目の変数の数 kmjm:2scale目の変数の数\n",
    "    kmjm = km*jm\n",
    "    len_X=len(X)\n",
    "    X1 = X[:km]\n",
    "    X2 = X[km:]\n",
    "    model = np.zeros(len_X)  # Initialize the model array\n",
    "    dX1 = np.zeros(km)\n",
    "    dX2 = np.zeros(kmjm)\n",
    "\n",
    "    for k in range(km):\n",
    "        dX1[k] = X1[(k - 1) % km] * (X1[(k + 1) % km] - X1[(k - 2) % km]) - X1[k] + F_ex - h * c / b * np.sum(X2[jm * k : jm * (k + 1)])\n",
    "    for j in range(kmjm):\n",
    "        dX2[j] = -c * b * X2[(j+1) % kmjm] * (X2[(j + 2) % kmjm] - X2[(j - 1) % kmjm]) - c * X2[j] + h * c / b * X1[(j // jm)]\n",
    "    model[:km] = dX1\n",
    "    model[km:] = dX2\n",
    "    return model\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def RK4(t,model, y0, dt, steps, *model_args):\n",
    "    \"\"\"\n",
    "    4次のルンゲクッタ法で微分方程式を数値積分する汎用関数。\n",
    "\n",
    "    Parameters:\n",
    "        model (function): 微分方程式モデル f(t, y, *args) を指定。\n",
    "                          t (float): 現在の時間\n",
    "                          y (array-like): 現在の状態ベクトル\n",
    "                          *args: モデルに渡す追加の引数\n",
    "        y0 (array-like): 初期状態ベクトル\n",
    "        dt (float): 時間刻み幅\n",
    "        steps (int): 積分するステップ数\n",
    "        *model_args: モデルに渡す追加の引数（任意）\n",
    "\n",
    "    Returns:\n",
    "        t (numpy.ndarray): 時間の配列\n",
    "        y (numpy.ndarray): 各時間ステップの状態ベクトル\n",
    "    \"\"\"\n",
    "    # y0 = np.array(y0)\n",
    "    # y = np.zeros((steps + 1, len(y0)))\n",
    "    # t = np.zeros(steps + 1)\n",
    "    # y[0] = y0\n",
    "    # t[0] = t0\n",
    "\n",
    "    y = y0\n",
    "    t = t0\n",
    "\n",
    "    for i in range(steps):\n",
    "        k1 = dt * model(t, y, *model_args)\n",
    "        k2 = dt * model(t + dt / 2, y + k1 / 2, *model_args)\n",
    "        k3 = dt * model(t + dt / 2, y + k2 / 2, *model_args)\n",
    "        k4 = dt * model(t + dt, y + k3, *model_args)\n",
    "\n",
    "\n",
    "        y = y + (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
    "        t = t + dt\n",
    "    return  y\n",
    "\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def compute_R_atr(true_data):\n",
    "    n = true_data.shape[0]\n",
    "    R_atr = 0.0\n",
    "    for k in range(n):\n",
    "        for l in range(k + 1, n):  # l_listに相当\n",
    "            diff = true_data[k] - true_data[l]\n",
    "            R_atr += np.sqrt(np.sum(diff ** 2))\n",
    "    R_atr = R_atr * 2.0 / (n * (n - 1))\n",
    "    return R_atr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate observation data by adding noise to true data\n",
    "rng = np.random.default_rng(2357)\n",
    "obs_data_x = true_data_x + rng.standard_normal(true_data_x.shape) ##ここだった!\n",
    "# obs_data_x = true_data_x + rng.standard_normal(len_x) ##ここだった!\n",
    "\n",
    "\n",
    "\n",
    "# Identity matrices for H and R\n",
    "H = np.identity(len_x)\n",
    "R = np.identity(len_x)\n",
    "H_inv = np.linalg.inv(H)\n",
    "R_inv = np.linalg.inv(R)\n",
    "\n",
    "\n",
    "\n",
    "# Analysis and forecast data arrays\n",
    "analyzed_data = np.zeros((n_data, len_x)) #(時系列数, 成分数)\n",
    "forecast_data = np.zeros((n_data, len_x))\n",
    "\n",
    "# Initial values for analysis and forecast\n",
    "#アトラクタ上の値から解析値の初期値を出す\n",
    "with open(\"1scale_x_initial_km40_F8.bin\", \"rb\") as i_x1:\n",
    "    init_data = np.frombuffer(i_x1.read(), dtype=np.float64)\n",
    "\n",
    "n_init = 1000\n",
    "init_data = init_data.reshape((n_init,km)) #true_data_x.reshape((n_data, km))\n",
    "\n",
    "print('init_data', init_data.shape)\n",
    "\n",
    "R_atr = compute_R_atr(init_data)\n",
    "\n",
    "# R_atr = compute_R_atr(true_data_x)\n",
    "\n",
    "print('R_atr=',R_atr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed = np.zeros((len_x,m))\n",
    "forecast = np.zeros((len_x,m))\n",
    "d_forecast = np.zeros((len_x,m)) #(成分数,アンサンブル数)\n",
    "d_obs = np.zeros((len_x,m))\n",
    "init_idx = list(np.arange(0,n_init))\n",
    "\n",
    "# while len(init_idx) < 2*m:\n",
    "#     init_idx.add(int(rng.integers(0,n_init)))\n",
    "\n",
    "\n",
    "\n",
    "# init_idx = list(init_idx)\n",
    "random.seed(1234)\n",
    "random.shuffle(init_idx)\n",
    "print('initial indices for analyzed',init_idx[:m])\n",
    "# print('initial indices for forecast',init_idx[m:2*m])\n",
    "\n",
    "ens=0\n",
    "for ens in range(m): #ensambleの作成\n",
    "    random_idx_anlz = init_idx[ens]\n",
    "    analyzed[:,ens] = init_data[random_idx_anlz,:] #use climatology as initial ensamble\n",
    "    # analyzed[:,ens] = true_data[0,:] +rng.standard_normal(len_x) #use t0's data as inital ensamble\n",
    "\n",
    "    # random_idx_fcst = init_idx[m+ens]\n",
    "    # forecast[:,ens] =init_data[random_idx_fcst,:] #+rng.standard_normal(km) * 1.e-2 #+ pert[ens]\n",
    "    # forecast[:,ens] =obs_data_x[0,:] +rng.standard_normal(km)*1.e-1 #not necessary\n",
    "    forecast[:,ens] =analyzed[:,ens] +rng.standard_normal(len_x)  #not necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "analyzed_data[0,:] = np.mean(analyzed,axis=1)\n",
    "forecast_data[0, :] = np.mean(forecast,axis=1)\n",
    "print('analyzed[0]', analyzed[0])\n",
    "# Trace arrays\n",
    "trace_P_a = np.zeros(n_data)\n",
    "trace_P_f = np.zeros(n_data)\n",
    "spread = np.zeros(n_data)\n",
    "\n",
    "P_a = np.identity(len_x) * R_atr\n",
    "trace_P_a[0] = np.trace(P_a)\n",
    "spread[0] = R_atr\n",
    "\n",
    "e=0\n",
    "for e in range(m):\n",
    "    d_forecast[:,e] = forecast[:,e] - forecast_data[0,:]\n",
    "\n",
    "P_f = d_forecast @d_forecast.T/(m-1)\n",
    "trace_P_f[0] = np.trace(P_f)\n",
    "\n",
    "# Main loop for assimilation\n",
    "# print(analyzed[:,0].shape)\n",
    "\n",
    "assim_time = np.zeros(n_data)\n",
    "assim_time[0] = data_time[0] #同化サイクルの時間発展\n",
    "\n",
    "ddT = np.zeros((len_x,len_x)) #use in adaptive multiplicative inf.\n",
    "\n",
    "\n",
    "# for i in range(1, 100):\n",
    "# for i in range(1):\n",
    "i=0\n",
    "for i in range(1, n_data):\n",
    "    # Forecast step using RK4\n",
    "    e=0\n",
    "    for e in range(m):\n",
    "        forecast[:,e] = RK4(assim_time[i-1],model_forecast, analyzed[:,e], dt, assimilation_interval, km) #i-1回目の解析値からi回目の予報値を計算\n",
    "\n",
    "    forecast_data[i] = np.mean(forecast,axis=1)#.reshape((km,1))\n",
    "\n",
    "#compute X_b & Y_b\n",
    "    e=0\n",
    "    for e in range(m):\n",
    "        d_forecast[:,e] = (forecast[:,e] - forecast_data[i,:])#.reshape((km,1))\n",
    "        d_obs[:,e] = H @ d_forecast[:,e] #(観測数,アンサンブル数) #linear observation\n",
    "        # d_obs[:,e] = H @ d_forecast[:,e].T #(観測数,アンサンブル数)\n",
    "\n",
    "        # d_obs[:,e] = H @ forecast[:,e] - H @ forecast_data[i] #(観測数,アンサンブル数)\n",
    "\n",
    "\n",
    "    # print('d_obs',d_obs, d_obs.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # #Adaptive multiplicative inflation\n",
    "    # increment= np.empty((len_obs,m))\n",
    "    e=0\n",
    "    # for e in range(m):\n",
    "    #     increment[:,e] = (obs_data_x[i] - H @ forecast[:,e]) #H:(l_x,l_x)\n",
    "\n",
    "    # ddT_past = ddT.copy()\n",
    "    # ddT = np.zeros((len_x,len_x))\n",
    "    e=0\n",
    "    # for e in range(m):\n",
    "    #     incre = increment[:,e].reshape((len_obs,1))\n",
    "    #     ddT += incre @ incre.T\n",
    "\n",
    "    # ddT = ddT/(m)\n",
    "\n",
    "    # if i > 2:\n",
    "    #     # rho =   np.trace(H_inv @ (ddT - R) @ H_inv.T) /np.trace(d_forecast @d_forecast.T/(len_x-1)) #P_f = d_forecast @d_forecast.T/(len_x-1)\n",
    "    #     rho = (np.trace((ddT * R_inv)) - R.size) / np.trace(H @ d_forecast @d_forecast.T/(len_x-1) @ H.T * R_inv)\n",
    "    # print('rho',rho)\n",
    "\n",
    "\n",
    "    #localization\n",
    "\n",
    "    C = d_obs.T @ np.linalg.inv(R) #(観測数,アンサンブル数).T@(観測数,観測数)→(アンサンブル数,観測数)\n",
    "\n",
    "\n",
    "    l,U = np.linalg.eig((((m-1) /rho) * np.identity(m)) + C @ d_obs)\n",
    "    D_1 = np.diag(l**-1.)\n",
    "    # P_a = U @ D_1 @ U.T  #P~a = UD^(-1)U.T\n",
    "\n",
    "    # D_2 = np.diag(np.sqrt(1./l))#ｌ^-0.5を対角成分にもつ行列D^-0.5の生成\n",
    "    D_2 = np.diag(l**-0.5)#ｌ^-0.5を対角成分にもつ行列D^-0.5の生成\n",
    "\n",
    "    dWa =  U @ D_2 @U.T\n",
    "\n",
    "    dWa = dWa * (m-1)**0.5   #いわゆるT(変換行列)\n",
    "    Pa_tild = dWa @ dWa /(m-1)  #P_a_tilder\n",
    "\n",
    "    P_f = d_forecast @d_forecast.T/(m-1)\n",
    "    P_a = d_forecast@Pa_tild@d_forecast.T\n",
    "\n",
    "\n",
    "    # # RTPP\n",
    "    # alpha = 0.96\n",
    "    # dWa = dWa * alpha + np.identity(m) * (1.-alpha)\n",
    "\n",
    "    # # RTPS\n",
    "    # alpha = 0.97\n",
    "    # sigma_fcst = (np.trace(P_f)/(m-1))**0.5\n",
    "    # sigma_anlz = (np.trace(P_a)/(m-1))**0.5\n",
    "    # # print('tr(P_a)',np.trace(P_a))\n",
    "    # # print('sigma_anlz',sigma_anlz)\n",
    "    # dWa *=   ((1.- alpha) * sigma_fcst +  alpha * sigma_anlz)/sigma_anlz\n",
    "\n",
    "    # P_a = dWa @ dWa /(m-1) #インフレーションを適用して再計算\n",
    "\n",
    "    ##not use eigenvalue decomp.\n",
    "    # P_a = np.linalg.inv((m-1)/rho * np.identity(m) + C @ d_obs)\n",
    "    # dWa = scipy.linalg.sqrtm((m-1)*P_a)\n",
    "    # print('dWa-dWa.T',(dWa-dWa.T).max())\n",
    "\n",
    "\n",
    "\n",
    "    wbar_a = Pa_tild @ C @(obs_data_x[i] - H @ forecast_data[i]) #(m,m)@(m,km)@(km,1) = (m,1)\n",
    "\n",
    "    W = dWa\n",
    "    e=0\n",
    "    for e in range(m):\n",
    "        W[:,e] += wbar_a\n",
    "        analyzed[:,e] = forecast_data[i] + d_forecast @ W[:,e]\n",
    "\n",
    "\n",
    "    analyzed_data[i] = np.mean(analyzed, axis=1)\n",
    "\n",
    "\n",
    "#RTPS\n",
    "    d_analyzed =(analyzed.T - analyzed_data[i]).T\n",
    "    alpha =0.\n",
    "    alpha_param=1.0\n",
    "    for n in range(km):\n",
    "        d_analyzed[n,:] *= 1.- alpha + alpha * np.linalg.norm(d_forecast[n,:])/np.linalg.norm(d_analyzed[n,:])\n",
    "    for n in range(km, len_x):\n",
    "        d_analyzed[n,:] *= 1. - alpha_param + alpha_param * np.linalg.norm(d_forecast[n,:])/np.linalg.norm(d_analyzed[n,:])\n",
    "    analyzed = (analyzed_data[i] + d_analyzed.T).T\n",
    "\n",
    "    P_a = d_analyzed@d_analyzed.T/(m-1)\n",
    "\n",
    "\n",
    "    if i <=1:\n",
    "        print('analyzed', analyzed.shape)\n",
    "        print('forecast_data['+str(i)+']', forecast_data[i].shape)\n",
    "        print('analyzed_data['+str(i)+']', analyzed_data[i].shape)\n",
    "        print('forecast[0,0]',forecast[0,0])\n",
    "\n",
    "\n",
    "    # analyzed_data[i,:] = forecast_data[i,:] + d_forecast@P_a@d_obs.T@np.linalg.inv(R)@(obs_data_x[i]-H@forecast_data[i,:])\n",
    "\n",
    "    trace_P_f[i] = np.trace(P_f)\n",
    "    trace_P_a[i] = np.trace(P_a) #Pa = Xb @Pa_tild @ Xb.T\n",
    "    spread[i] = np.mean([np.linalg.norm(analyzed[:,_]-analyzed.mean(axis=1) )for _ in range(m)])/len_x**0.5\n",
    "    assim_time[i] = assim_time[i-1] + dt * assimilation_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(np.sqrt(P_f[n,n]/P_a[n,n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs((P_f[n,n]/P_a[n,n]))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_f[n,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_a[n,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE\n",
    "RMSE_obs_x1 = np.linalg.norm(obs_data_x[:,:km] - true_data_x[:,:km], axis=1) / km ** 0.5\n",
    "RMSE_forecast_x1 = np.linalg.norm(forecast_data[:,:km] - true_data_x[:,:km], axis=1) / km ** 0.5\n",
    "RMSE_analysis_x1 = np.linalg.norm(analyzed_data[:,:km] - true_data_x[:,:km], axis=1) / km ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig1=plt.figure(figsize=(8,4))\n",
    "ax1 = fig1.add_subplot(111)\n",
    "# spread=(trace_P_a/(m-1))**0.5\n",
    "ax1.plot((data_time-data_time[0])/(dt*assimilation_interval), RMSE_obs_x1, label=\"Observation RMSE\")\n",
    "ax1.plot((assim_time-assim_time[0])/(dt*assimilation_interval), RMSE_forecast_x1, label=\"Forecast RMSE: \"+str(np.mean(RMSE_forecast_x1)))\n",
    "ax1.plot((assim_time-assim_time[0])/(dt*assimilation_interval), RMSE_analysis_x1, label=\"Analysis RMSE: \"+str(np.mean(RMSE_analysis_x1)), alpha=1.)\n",
    "ax1.plot((assim_time-assim_time[0])/(dt*assimilation_interval), spread, label='Spread: '+str(np.mean(spread)))\n",
    "ax1.axhline(0.2, color='k', linestyle='--', label=\"0.2\")\n",
    "\n",
    "ax1.set_xlabel(\"Assimilation step\")\n",
    "# ax1.set_ylim((-0.5,1.5))\n",
    "ax1.legend()\n",
    "ax1.set_title('RMSEs (ETKF)')\n",
    "\n",
    "plt.show()\n",
    "print(np.mean(RMSE_analysis_x1[1000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot results\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(312)\n",
    "ax2.plot((assim_time-assim_time[0])/(dt*assimilation_interval), trace_P_a, label='tr(P$_a$)')\n",
    "\n",
    "# ax2.axhline(0.2, color='red', linestyle='--', label=\"0.2\")\n",
    "\n",
    "ax2.set_xlabel(\"Timestep\")\n",
    "ax2.set_ylim((0,10))\n",
    "ax2.legend()\n",
    "\n",
    "# Plot results\n",
    "ax3 = fig2.add_subplot(313)\n",
    "ax3.plot((assim_time-assim_time[0])/(dt*assimilation_interval), trace_P_f, label='tr(P$_f$)')\n",
    "\n",
    "# ax2.axhline(0.2, color='red', linestyle='--', label=\"0.2\")\n",
    "\n",
    "ax3.set_xlabel(\"Timestep\")\n",
    "ax3.set_ylim((-0,10))\n",
    "ax3.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tend =200\n",
    "# Plot results\n",
    "fig2 = plt.figure(figsize=(14,4))\n",
    "ax2 = fig2.add_subplot(121)\n",
    "ax2.plot((assim_time[:Tend]-assim_time[0])/(dt*assimilation_interval), forecast_data[:Tend,0], label='Forecast', color='r', linestyle='--')\n",
    "\n",
    "ax2.plot((assim_time[:Tend]-assim_time[0])/(dt*assimilation_interval), true_data_x[:Tend,0], label='True', color='lime')\n",
    "\n",
    "ax2.scatter((assim_time[:Tend]-assim_time[0])/(dt*assimilation_interval), obs_data_x[:Tend,0], label='Observation', color='b', s=5)\n",
    "ax2.set_ylabel(\"x$_{1}$\")\n",
    "ax2.set_xlabel(\"Assimilation Timestep\")\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "# Plot results\n",
    "ax3 = fig2.add_subplot(122)\n",
    "# Plot results\n",
    "ax3.plot((data_time[:Tend]-data_time[0])/(dt*assimilation_interval), RMSE_obs_x1[:Tend], label=\"Observation\", color='b')\n",
    "ax3.plot((assim_time[:Tend]-assim_time[0])/(dt*assimilation_interval), RMSE_forecast_x1[:Tend], label=\"Forecast\", color='r')\n",
    "\n",
    "# ax2.axhline(0.2, color='red', linestyle='--', label=\"0.2\")\n",
    "\n",
    "ax3.set_xlabel(\"Assimilation Timestep\")\n",
    "ax3.set_ylabel(\"RMSE\")\n",
    "\n",
    "\n",
    "ax3.set_ylim((-0,5))\n",
    "ax3.legend()\n",
    "fig2.suptitle('Data assimilation with ETKF')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameter survey\n",
    "# rho_values = np.arange(1.0, 1.51, 0.01)  # rhoを1.0から1.5まで0.01刻み\n",
    "# n_rho = len(rho_values)  # rhoの値の個数\n",
    "\n",
    "# # ヒートマップ用のRMSE配列を初期化\n",
    "# RMSE_heatmap = np.zeros((n_rho, n_data))\n",
    "\n",
    "# for idx, rho in enumerate(rho_values):\n",
    "#     # rhoを変更してシミュレーションを実行\n",
    "#     analyzed_data = np.zeros((n_data, len_x))\n",
    "#     forecast_data = np.zeros((n_data, len_x))\n",
    "\n",
    "#     # 初期値設定（コード内から流用）\n",
    "#     analyzed = np.zeros((len_x, m))\n",
    "#     forecast = np.zeros((len_x, m))\n",
    "#     for ens in range(m):\n",
    "#         analyzed[:km, ens] += 0 + rng.standard_normal(km)\n",
    "#         forecast[:, ens] = obs_data_x[0, :]\n",
    "\n",
    "#     analyzed_data[0, :] = np.mean(analyzed, axis=1)\n",
    "#     forecast_data[0, :] = np.mean(forecast, axis=1)\n",
    "\n",
    "#     for i in range(1, n_data):\n",
    "#         for e in range(m):\n",
    "#             forecast[:, e] = RK4(assim_time[i-1], model_forecast, analyzed[:, e], dt, assimilation_interval, km)\n",
    "\n",
    "#         forecast_data[i] = np.mean(forecast, axis=1)\n",
    "\n",
    "#         for e in range(m):\n",
    "#             d_forecast[:, e] = forecast[:, e] - forecast_data[i]\n",
    "#             d_obs[:, e] = H @ forecast[:, e] - H @ forecast_data[i]\n",
    "\n",
    "#         C = d_obs.T @ np.linalg.inv(R)\n",
    "#         l, U = np.linalg.eig((m-1)/rho * np.identity(m) + C @ d_obs)\n",
    "#         D_1 = np.diag(1./l)\n",
    "#         P_a = U @ D_1 @ U.T\n",
    "#         D_2 = np.diag(np.sqrt(1./l))\n",
    "#         W_a = U @ D_2 @ U.T * np.sqrt(m-1)\n",
    "#         wbar_a = P_a @ C @ (obs_data_x[i] - H @ forecast_data[i])\n",
    "\n",
    "#         for e in range(m):\n",
    "#             W_a[e] += wbar_a\n",
    "#             analyzed[:, e] = d_forecast @ W_a[e, :] + forecast_data[i]\n",
    "\n",
    "#         analyzed_data[i] = np.mean(analyzed, axis=1)\n",
    "\n",
    "#     RMSE_forecast_x1 = np.linalg.norm(forecast_data[:, :km] - true_data_x[:, :km], axis=1) / km ** 0.5\n",
    "#     RMSE_heatmap[idx, :] = RMSE_forecast_x1\n",
    "\n",
    "# # ヒートマップの描画\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.imshow(RMSE_heatmap, aspect='auto', extent=[0, n_data, 1.0, 1.5], origin='lower', cmap='viridis')\n",
    "# plt.colorbar(label=\"RMSE_forecast_x1\")\n",
    "# plt.xlabel(\"Time step\")\n",
    "# plt.ylabel(\"rho\")\n",
    "# plt.title(\"Heatmap of RMSE_forecast_x1\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./1scaleL96_RMSE_forecast_heatmap.npy',RMSE_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tend =200\n",
    "# Plot results\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111, projection='3d')\n",
    "\n",
    "ax2.plot(true_data_x[Tend:,0],true_data_x[Tend:,14],true_data_x[Tend:,24])\n",
    "\n",
    "\n",
    "ax2.set_ylabel(\"x$_{1}$\")\n",
    "ax2.set_ylabel(\"x$_{15}$\")\n",
    "ax2.set_ylabel(\"x$_{25}$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE_forecast_x1 の最小値を持つ rho を計算\n",
    "# min_rmse_idx = np.unravel_index(np.argmin(RMSE_heatmap), RMSE_heatmap.shape)\n",
    "# rho_min_rmse = rho_values[min_rmse_idx[0]]\n",
    "\n",
    "# # RMSE_forecast_x1[1:] の平均を最小化する rho を計算\n",
    "# mean_rmse_per_rho = np.mean(RMSE_heatmap[:, :-1000], axis=1)  # 時系列ラスト100個の平均\n",
    "# rho_min_mean_rmse = rho_values[np.argmin(mean_rmse_per_rho)]\n",
    "\n",
    "# # ヒートマップの描画\n",
    "# plt.figure(figsize=(16, 9))\n",
    "# plt.imshow(RMSE_heatmap, aspect='auto', extent=[0, n_data, 1.0, 1.5], origin='lower', cmap='viridis')\n",
    "# plt.colorbar(label=\"RMSE_forecast_x1\")\n",
    "# plt.xlabel(\"Time step\")\n",
    "# plt.ylabel(\"rho\")\n",
    "# plt.title(\"Heatmap of RMSE_forecast_x1\")\n",
    "\n",
    "# # 最小 RMSE の位置に hline を追加\n",
    "# plt.axhline(y=rho_min_rmse, color='red', linestyle='--', label=f\"Min RMSE rho = {rho_min_rmse:.2f}\")\n",
    "\n",
    "# # 平均 RMSE を最小化する rho の位置に hline を追加\n",
    "# plt.axhline(y=rho_min_mean_rmse, color='blue', linestyle='--', label=f\"Min Avg RMSE rho = {rho_min_mean_rmse:.2f}\")\n",
    "\n",
    "# # 凡例を追加\n",
    "# plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ETKF(i, analyzed_pre, model,y0, dt, steps, *model_args):\n",
    "#     # for i in range(1, n_data):\n",
    "#     # # for i in range(1):\n",
    "#     #     # Forecast step using RK4\n",
    "#     #     for e in range(m):\n",
    "#     #         forecast[:,e] = RK4(assim_time[i-1],model_forecast, analyzed[:,e], dt, assimilation_interval, km) #i-1回目の解析値からi回目の予報値を計算\n",
    "\n",
    "#     #     forecast_data[i] = np.mean(forecast,axis=1)#.reshape((km,1))\n",
    "\n",
    "\n",
    "#     #     for e in range(m):\n",
    "#     #         d_forecast[:,e] = (forecast[:,e] - forecast_data[i])#.reshape((km,1))\n",
    "#     #         # d_obs[:,e] = H @ forecast[:,e] - H @ forecast_data[i] #(観測数,アンサンブル数)\n",
    "#     #         d_obs[:,e] = H @ forecast[:,e] - H @ forecast_data[i] #(観測数,アンサンブル数)\n",
    "\n",
    "\n",
    "#     #     # print('d_obs',d_obs, d_obs.shape)\n",
    "#     #     # print('d_obs.T @ np.linalg.inv(R) @ d_obs', (d_obs.T @ np.linalg.inv(R) @ d_obs).shape)\n",
    "\n",
    "\n",
    "#     #     # #Adaptive multiplicative inflation\n",
    "#     #     # increment= np.empty((len_obs,m))\n",
    "#     #     # for e in range(m):\n",
    "#     #     #     increment[:,e] = (obs_data_x[i] - H @ forecast[:,e]) #H:(l_x,l_x)\n",
    "\n",
    "#     #     # ddT_past = ddT.copy()\n",
    "#     #     # ddT = np.zeros((len_x,len_x))\n",
    "\n",
    "#     #     # for e in range(m):\n",
    "#     #     #     incre = increment[:,e].reshape((len_obs,1))\n",
    "#     #     #     ddT += incre @ incre.T\n",
    "\n",
    "#     #     # ddT = ddT/(m)\n",
    "\n",
    "#     #     # if i > 2:\n",
    "#     #     #     # rho =   np.trace(H_inv @ (ddT - R) @ H_inv.T) /np.trace(d_forecast @d_forecast.T/(len_x-1)) #P_f = d_forecast @d_forecast.T/(len_x-1)\n",
    "#     #     #     rho = (np.trace((ddT * R_inv)) - R.size) / np.trace(H @ d_forecast @d_forecast.T/(len_x-1) @ H.T * R_inv)\n",
    "#     #     # print('rho',rho)\n",
    "\n",
    "\n",
    "#     #     #localization\n",
    "\n",
    "\n",
    "\n",
    "#     #     C = d_obs.T @ np.linalg.inv(R)\n",
    "#     #     l,U = np.linalg.eig((m-1)/rho * np.identity(m) + C @ d_obs)\n",
    "\n",
    "#     #     D_1 = np.diag(1./l)\n",
    "#     #     P_a = U @ D_1 @ U.T  #P~a = UD^(-1)U.T\n",
    "#     #     P_f = d_forecast @d_forecast.T/(len_x-1)\n",
    "\n",
    "#     #     # D_2 = np.diag(1./np.sqrt(l))#ｌ^-0.5を対角成分にもつ行列D^-0.5の生成\n",
    "#     #     D_2 = np.diag(np.sqrt(1./l))#ｌ^-0.5を対角成分にもつ行列D^-0.5の生成\n",
    "\n",
    "#     #     W_a =  U @ D_2 @U.T * np.sqrt(m-1)\n",
    "\n",
    "#     #     wbar_a = P_a @ C @(obs_data_x[i] - H @ forecast_data[i])\n",
    "\n",
    "#     #     for e in range(m):\n",
    "#     #         # W_a[:,e] += wbar_a  #(m,m)行列の各列に(m)ベクトルを足す\n",
    "#     #         W_a[e] += wbar_a  #(m,m)行列の各行に(m)ベクトルを足す　たぶんこっちが正しい\n",
    "\n",
    "#     #         analyzed[:,e] = d_forecast @ W_a[e,:] + forecast_data[i]\n",
    "#     #         # analyzed[:,e] = (d_forecast @ W_a[e,:]).T  + forecast_data[i] #転置とってみた\n",
    "\n",
    "\n",
    "\n",
    "#     #     # l,U = np.linalg.eig((m-1)/rho * np.identity(m) + d_obs.T @ np.linalg.inv(R) @ d_obs)\n",
    "#     #     # print('l[0]:',l[0])\n",
    "#     #     # l[0] = np.mean(l[1:])\n",
    "#     #     # print('l[0]:',l[0])\n",
    "#     #     # D_2 = np.diag(np.sqrt(1./l))#ｌ^-0.5を対角成分にもつ行列D^-0.5の生成\n",
    "#     #     # D_2 = np.diag(1./np.sqrt(l))#ｌ^-0.5を対角成分にもつ行列D^-0.5の生成\n",
    "\n",
    "#     #     # analyzed =  d_forecast @ (P_a @ d_obs.T @ np.linalg.inv(R) @ (obs_data_x[i] - np.mean(H @ forecast, axis=1)) + np.sqrt(m-1)*U @ D_2 @ U.T) #(成分数, アンサンブル数)\n",
    "\n",
    "\n",
    "#     #     # analyzed += forecast_data[i,:].reshape((72,1))\n",
    "\n",
    "#     #     analyzed_data[i] = np.mean(analyzed, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
